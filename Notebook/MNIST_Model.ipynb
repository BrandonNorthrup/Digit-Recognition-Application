{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as pyplot\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pandas\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-spencer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the MNIST dataset that comes included with Keras\n",
    "(data_training, labels_training), (data_testing, labels_testing) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape each image from the data into 28x28 pixels\n",
    "data_training = data_training.reshape(data_training.shape[0], 28, 28, 1)\n",
    "data_testing = data_testing.reshape(data_testing.shape[0], 28, 28, 1)\n",
    "\n",
    "# Assign the labels for reference\n",
    "labels_training = keras.utils.to_categorical(labels_training)\n",
    "labels_testing = keras.utils.to_categorical(labels_testing)\n",
    "\n",
    "# Change values to float\n",
    "data_training = data_training.astype('float32')\n",
    "data_testing = data_testing.astype('float32')\n",
    "\n",
    "# Change to a value between 0 and 1\n",
    "# In this case, 0 indicates white, 1 indicates black\n",
    "data_training /= 255\n",
    "data_testing /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount of times the model will run back and forth through the training data\n",
    "epochs = 10\n",
    "\n",
    "# Amount of data that goes through at one time, generally a power of 2\n",
    "batch_size = 64\n",
    "\n",
    "# Define a model that uses layers in a sequential order\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 32 filters and 3x3 kernel_size, include the input_shape for the first layer\n",
    "# Convolutional layers essentially map out the data\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = \"relu\", input_shape = (28, 28, 1)))\n",
    "\n",
    "# Add a convolutional layer with 64 filters and 3x3 kernel_size\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = \"relu\"))\n",
    "\n",
    "# Add a convolutional layer with 128 filters and 3x3 kernel_size\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = \"relu\"))\n",
    "\n",
    "# Add a layer that takes a 2x2 window (4 pixels) and chooses the pixel with the highest black value\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Add a layer that prevents overfitting, with a 50% chance of \"forgetting\" previous information\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add a layer that effectively reduces the number of dimensions\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a fully connected neural network layer\n",
    "model.add(Dense(64, activation = \"relu\"))\n",
    "\n",
    "# Add a layer that prevents overfitting, with a 20% chance of \"forgetting\" previous information\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Add a fully connected neural network layer, using softmax to interpret the result as a probability\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "# Compile the layers and use the Adam optimizer, cross entropy loss, and accuracy as the metrics\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training the data and assign the results to model_history\n",
    "model_history = model.fit(data_training,\n",
    "                          labels_training,\n",
    "                          batch_size = batch_size,\n",
    "                          epochs = epochs,\n",
    "                          verbose = 1,\n",
    "                          validation_data = (data_testing, labels_testing))\n",
    "\n",
    "# Save the model as an HDF5 file for use in the dashboard and print a message indicating that it has finished\n",
    "model.save(\"digit_recognizer_model.hdf5\")\n",
    "print(\"Model trained!\")\n",
    "\n",
    "# Save the model history as a NumPy file for use in the dashboard and print a message indicating that it has finished\n",
    "np.save('model_history.npy', model_history.history)\n",
    "print(\"Model history saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-campus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
